import{_ as a,c as n,o as s,ae as p}from"./chunks/framework.Cd-3tpCq.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"frontend/05网络协议与安全/概述http1.0、http1.1、 http2.0特性.md","filePath":"frontend/05网络协议与安全/概述http1.0、http1.1、 http2.0特性.md"}'),l={name:"frontend/05网络协议与安全/概述http1.0、http1.1、 http2.0特性.md"};function e(o,t,r,i,h,g){return s(),n("div",null,t[0]||(t[0]=[p(`<h2 id="http1-0特性" tabindex="-1">http1.0特性 <a class="header-anchor" href="#http1-0特性" aria-label="Permalink to &quot;http1.0特性&quot;">​</a></h2><h4 id="无状态" tabindex="-1">无状态 <a class="header-anchor" href="#无状态" aria-label="Permalink to &quot;无状态&quot;">​</a></h4><p><strong>服务器不跟踪不记录请求的状态</strong>。<strong>对于无状态的特性可以借助cookie/session机制来做身份认证和状态记录</strong></p><h4 id="无连接" tabindex="-1">无连接 <a class="header-anchor" href="#无连接" aria-label="Permalink to &quot;无连接&quot;">​</a></h4><p><strong>浏览器每次请求都需要建立tcp连接。无连接会导致两种性能缺陷：</strong></p><p><strong>1. 无法复用连接</strong><strong>每次发送请求，都需要进行一次tcp连接（即3次握手4次挥手），使得网络的利用率非常低</strong></p><p><strong>2. 队头阻塞</strong><strong>http1.0规定在前一个请求响应到达之后下一个请求才能发送，如果前一个阻塞，后面的请求也会阻塞的</strong></p><h2 id="http1-1特性" tabindex="-1">http1.1特性 <a class="header-anchor" href="#http1-1特性" aria-label="Permalink to &quot;http1.1特性&quot;">​</a></h2><p>为了解决<code>http1.0</code>的性能缺陷，改造优化后出现<code>http1.1</code>，其中有几个重要特性：</p><ul><li><p>长连接：</p><ul><li>新增Connection字段，可以设置keep-alive值保持连接不断开，<strong>http1.1默认使用keep-alive保持长连接，数据传输完成保持tcp连接不断开,继续用这个通道传输数据</strong></li></ul></li><li><p>管道化：</p><ul><li><strong>在长连接的基础上，可以不等第一个请求的响应继续发送后面的请求，但响应的顺序还是按照请求的顺序返回，仍然无法解决队头阻塞的问题</strong></li></ul><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>// 基于长连接的基础，我们先看没有管道化请求响应：</span></span>
<span class="line"><span>// tcp没有断开，用的同一个通道</span></span>
<span class="line"><span>请求1 &gt; 响应1 --&gt; 请求2 &gt; 响应2 --&gt; 请求3 &gt; 响应3</span></span>
<span class="line"><span>// 管道化的请求响应：</span></span>
<span class="line"><span>请求1 --&gt; 请求2 --&gt; 请求3 &gt; 响应1 --&gt; 响应2 --&gt; 响应3</span></span>
<span class="line"><span></span></span>
<span class="line"><span>即使服务器先准备好响应2,也是按照请求顺序先返回响应1，虽然管道化，可以一次发送多个请求，但是响应仍是顺序返回，仍然无法解决队头阻塞的问题</span></span></code></pre></div></li><li><p>缓存处理：新增字段cache-control来控制</p><ul><li><strong>当浏览器请求资源时，先看是否有缓存的资源，如果有缓存，直接取，不会再发请求，如果没有缓存，则发送请求</strong></li></ul></li><li><p>断点传输：借助Header的<strong>Range</strong>(客户端发请求)和<strong>Content-Range</strong>(服务器端响应)两个参数实现的</p><ul><li><strong>在上传/下载资源时，如果资源过大，将其分割为多个部分，分别上传/下载，如果遇到网络故障，可以从已经上传/下载好的地方继续请求，不用从头开始，提高效率</strong></li></ul></li></ul><h2 id="http2-0特性" tabindex="-1">http2.0特性 <a class="header-anchor" href="#http2-0特性" aria-label="Permalink to &quot;http2.0特性&quot;">​</a></h2><ul><li><p><strong>多路复用</strong>： 在共享TCP链接的基础上同时发送请求和接收响应</p><ul><li><p>在 HTTP/1 中，每次请求都会建立一次HTTP连接，也就是我们常说的3次握手4次挥手，这个过程在一次请求过程中占用了相当长的时间，即使开启了 Keep-Alive ，解决了多次连接的问题，但是依然有两个效率上的问题：</p><ul><li>第一个：<strong>串行的文件传输。当请求a文件时，b文件只能等待</strong>，等待a连接到服务器、服务器处理文件、服务器返回文件，这三个步骤。我们假设这三步用时都是1秒，那么a文件用时为3秒，b文件传输完成用时为6秒，依此类推。（注：此项计算有一个前提条件，就是浏览器和服务器是单通道传输）</li><li>第二个：<strong>连接数过多。<strong>我们假设Apache设置了最大并发数为300，因为浏览器限制，浏览器发起的最大请求数为6，也就是服务器能承载的最高并发为50，当第51个人访问时，就</strong>需要等待前面某个请求处理完成</strong>。</li></ul><p>HTTP/2的多路复用就是为了解决上述的两个性能问题。</p></li><li><p>二进制分帧</p><ul><li>在 HTTP/2 中，有两个非常重要的概念，分别是帧（frame）和流（stream）。帧代表着被分割成的最小的数据单位，采用<strong>二进制格式的编码</strong>， <strong>每个帧会标识出该帧属于哪个流</strong>，流也就是多个帧组成的数据流。</li></ul></li><li><p><strong>多路复用，就是在一个 TCP 连接中可以存在多条流。基于二进制分帧，在同一域名下所有访问都是从同一个tcp连接中走，http消息被分解为独立的帧，乱序发送，服务端根据帧中的标识符和首部将消息重新组装起来</strong>，通过这个技术，可以避免 HTTP 旧版本中的队头阻塞问题，极大的提高传输性能。</p></li><li><p>补充：<a href="https://github.com/Advanced-Frontend/Daily-Interview-Question/issues/290" target="_blank" rel="noreferrer">http2队头阻塞问题</a></p><ul><li>http2.0 也存在队头阻塞问题，如果造成队头阻塞，问题可能比http1.1还严重，因为只有一个tcp连接，后续的传输都要等前面，http1.1 多个tcp连接，阻塞一个，其他的还可以正常跑</li><li>对的，这也是为什么http3.0出来的主要原因之一。在HTTP/2中，多个请求是跑在一个TCP管道中的。但当出现了丢包时，HTTP/2 的表现反倒不如 HTTP/1 了。因为TCP为了保证可靠传输，有个特别的“丢包重传”机制，丢失的包必须要等待重新传输确认，HTTP/2出现丢包时，整个 TCP 都要开始等待重传，那么就会阻塞该TCP连接中的所有请求（如下图）。而对于 HTTP/1.1 来说，可以开启多个 TCP 连接，出现这种情况反到只会影响其中一个连接，剩余的 TCP 连接还可以正常传输数据。</li></ul></li></ul></li><li><p>header压缩</p></li><li><p>服务器推送：服务器可以额外的向客户端推送资源，而无需客户端明确的请求</p></li></ul><h2 id="区别" tabindex="-1">区别 <a class="header-anchor" href="#区别" aria-label="Permalink to &quot;区别&quot;">​</a></h2><ol><li>http1.0 到http1.1的主要区别，就是<strong>从无连接到长连接</strong></li><li>http2.0对比1.X版本主要区别就是<strong>多路复用</strong></li></ol>`,14)]))}const u=a(l,[["render",e]]);export{d as __pageData,u as default};
